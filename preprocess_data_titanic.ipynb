{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39b5415b-f2d9-4142-bd69-b5422ad93aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId     0.000000\n",
      "Survived        0.000000\n",
      "Pclass          0.000000\n",
      "Name            0.000000\n",
      "Sex             0.000000\n",
      "Age            19.865320\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Ticket          0.000000\n",
      "Fare            0.000000\n",
      "Cabin          77.104377\n",
      "Embarked        0.224467\n",
      "dtype: float64\n",
      "   PassengerId  Survived  Pclass                            Name     Sex  \\\n",
      "0            1         0       3         Braund, Mr. Owen Harris    male   \n",
      "2            3         1       3          Heikkinen, Miss. Laina  female   \n",
      "4            5         0       3        Allen, Mr. William Henry    male   \n",
      "5            6         0       3                Moran, Mr. James    male   \n",
      "7            8         0       3  Palsson, Master. Gosta Leonard    male   \n",
      "\n",
      "    Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4  35.0      0      0            373450   8.0500   NaN        S  \n",
      "5   NaN      0      0            330877   8.4583   NaN        Q  \n",
      "7   2.0      3      1            349909  21.0750   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 1) Carregar dataset Titanic\n",
    "df = pd.read_csv(\"data/raw/titanic.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# 2) Checar valores nulos\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().mean() * 100)\n",
    "print(df[df.isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64c0068c-23a7-425f-8b70-e27e2ebd39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas com mais de 50% de nulos\n",
    "df_menos_colunas = df.dropna(axis=1, thresh=0.5*len(df))\n",
    "\n",
    "# Preencher numéricos com mediana\n",
    "df_preenchido = df.fillna(df.median(numeric_only=True))\n",
    "df_preenchido['Age'] = df_preenchido['Age'].astype(int)\n",
    "\n",
    "# Preencher categóricos com moda\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df_preenchido[col] = df_preenchido[col].fillna(df[col].mode()[0])\n",
    "\n",
    "df_preenchido.to_csv(\"data/processed/titanic_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "405e50ae-971f-4092-bb4a-67653480b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de outliers detectados por coluna:\n",
      "PassengerId: 0\n",
      "Survived: 0\n",
      "Pclass: 0\n",
      "Age: 66\n",
      "SibSp: 46\n",
      "Parch: 213\n",
      "Fare: 116\n"
     ]
    }
   ],
   "source": [
    "def detectar_outliers(col):\n",
    "    Q1 = col.quantile(0.25)\n",
    "    Q3 = col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    return col[(col < limite_inferior) | (col > limite_superior)]\n",
    "\n",
    "outliers = {}\n",
    "for col in df_preenchido.select_dtypes(include=[np.number]).columns:\n",
    "    outliers[col] = detectar_outliers(df_preenchido[col])\n",
    "\n",
    "print(\"\\nQuantidade de outliers detectados por coluna:\")\n",
    "for col, vals in outliers.items():\n",
    "    print(f\"{col}: {len(vals)}\")\n",
    "\n",
    "# Substituir outliers pela mediana\n",
    "df_tratado = df_preenchido.copy()\n",
    "for col in df_tratado.select_dtypes(include=[np.number]).columns:\n",
    "    Q1 = df_tratado[col].quantile(0.25)\n",
    "    Q3 = df_tratado[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    mediana = df_tratado[col].median()\n",
    "    df_tratado.loc[(df_tratado[col] < limite_inferior) | (df_tratado[col] > limite_superior), col] = mediana\n",
    "\n",
    "df_tratado.to_csv(\"data/processed/titanic_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19d9fdba-954b-4d4c-b988-2f6a04f71bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de dados antes da conversão:\n",
      " PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age              int64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "Colunas categóricas detectadas: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\n",
      "Dimensões após encoding: (891, 1726)\n",
      "Tipos de dados depois da conversão:\n",
      " PassengerId    int64\n",
      "Survived       int64\n",
      "Pclass         int64\n",
      "Age            int64\n",
      "SibSp          int64\n",
      "               ...  \n",
      "Cabin_F4        bool\n",
      "Cabin_G6        bool\n",
      "Cabin_T         bool\n",
      "Embarked_Q      bool\n",
      "Embarked_S      bool\n",
      "Length: 1726, dtype: object\n",
      "\n",
      "Dataset convertido salvo em data/processed/titanic_ml_ready.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/titanic_final.csv\")\n",
    "\n",
    "print(\"Tipos de dados antes da conversão:\\n\", df.dtypes)\n",
    "\n",
    "cols_categoricas = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"Colunas categóricas detectadas:\", cols_categoricas)\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "df_numerico = pd.get_dummies(df, columns=cols_categoricas, drop_first=True)\n",
    "\n",
    "print(\"\\nDimensões após encoding:\", df_numerico.shape)\n",
    "print(\"Tipos de dados depois da conversão:\\n\", df_numerico.dtypes)\n",
    "\n",
    "df_numerico.to_csv(\"data/processed/titanic_ml_ready.csv\", index=False)\n",
    "print(\"\\nDataset convertido salvo em data/processed/titanic_ml_ready.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e55af500-ba55-4e78-96a3-1e645eaac235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes da normalização:\n",
      "             count        mean         std  min    25%    50%    75%    max\n",
      "PassengerId  891.0  446.000000  257.353842  1.0  223.5  446.0  668.5  891.0\n",
      "Survived     891.0    0.383838    0.486592  0.0    0.0    0.0    1.0    1.0\n",
      "Pclass       891.0    2.308642    0.836071  1.0    2.0    3.0    3.0    3.0\n",
      "Age          891.0   28.468013    9.790722  3.0   23.5   28.0   33.0   54.0\n",
      "SibSp        891.0    0.297419    0.521648  0.0    0.0    0.0    1.0    2.0\n",
      "\n",
      "Datasets salvos:\n",
      "StandardScaler: data/processed/titanic_ml_standard.csv\n",
      "MinMaxScaler:   data/processed/titanic_ml_minmax.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed/titanic_ml_ready.csv\")\n",
    "\n",
    "print(\"Antes da normalização:\")\n",
    "print(df.describe().T.head())\n",
    "\n",
    "y = df[\"Survived\"] if \"Survived\" in df.columns else None\n",
    "X = df.drop(columns=[\"Survived\"]) if \"Survived\" in df.columns else df\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "X_std = pd.DataFrame(scaler_std.fit_transform(X), columns=X.columns)\n",
    "\n",
    "scaler_mm = MinMaxScaler()\n",
    "X_mm = pd.DataFrame(scaler_mm.fit_transform(X), columns=X.columns)\n",
    "\n",
    "if y is not None:\n",
    "    df_std = pd.concat([X_std, y], axis=1)\n",
    "    df_mm = pd.concat([X_mm, y], axis=1)\n",
    "else:\n",
    "    df_std, df_mm = X_std, X_mm\n",
    "\n",
    "df_std.to_csv(\"data/processed/titanic_ml_standard.csv\", index=False)\n",
    "df_mm.to_csv(\"data/processed/titanic_ml_minmax.csv\", index=False)\n",
    "\n",
    "print(\"\\nDatasets salvos:\")\n",
    "print(\"StandardScaler: data/processed/titanic_ml_standard.csv\")\n",
    "print(\"MinMaxScaler:   data/processed/titanic_ml_minmax.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4f205-a1d5-4e95-9187-eeeb02e59b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
